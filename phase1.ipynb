{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Clark-Wright Savings Algorithm\n",
    "\n",
    "The savings algorithm aims to find a solution to the Vechile Routing Problem (VRP). It starts off with a trivial solution where there are $n$ vehicles which deliver to $n$ nodes. It then merges routes based on the highest possible savings per merge. The idea is to be able to start with the image on the left and move to the image on the right. \n",
    "\n",
    "<img src=img/clark.png width=\"300\" height=\"200\" />\n",
    "\n",
    "\n",
    "Basically the algorithm can be understood as follows: \n",
    "<ol>\n",
    "  <li>Start off with a trivial solution to the problem. That is, have one vechicle travel from the depot to each node.</li>\n",
    "  <li>Create a savings matrix such that s(i, j) = distance(i, depot) + distance(depot, j) - distance(i, j)</li>\n",
    "  <li>Sort your savings matrix so you consider the pairs with the highest savings first</li>\n",
    "  <li>Merge those nodes if they meet all the feasibility constraints</li>\n",
    "</ol>         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "timedf             = pd.read_csv('data/PrepSiteTimeMatrix.csv', header=0, index_col=0)\n",
    "prep_carry_matches = pd.read_csv('data/prep-carry-matches2.csv')\n",
    "delivery_times     = pd.read_csv('data/delivery-times2.csv')\n",
    "prep_carry_matches = prep_carry_matches.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining all the segments. Each segment has one prep site, one/two carry-in sites, and one timewindow\n",
    "#\n",
    "# Ex: Segment 0 -> Prep Site = 450 | Carry-Ins = [604,] | Time-Window = (6:15, 7:15)\n",
    "#     Segment 1 -> Prep Site = 450 | Carry-Ins = [604,] | Time-Windwo = (9:30, 10:30)\n",
    "segments = []\n",
    "for i in prep_carry_matches.values.tolist():\n",
    "    x = (int(i[0]), int(i[1]), int(i[2]))\n",
    "    segments.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Time Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_lookup(carryin_):\n",
    "    for i in delivery_times.values:\n",
    "        if i[0] == carryin_:\n",
    "            return list(i)\n",
    "    raise Exception(f'carryin site {carryin_} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a segment that has one or two carry-in sites, it builds a time window for that segment\n",
    "# The start of the window is considered the earliest arrival time, and the end of the window is considered the \n",
    "# earliest departure time\n",
    "\n",
    "def window_builder(segments_):\n",
    "    windows = {}\n",
    "    seen = {}\n",
    "    visited = {}\n",
    "    for segment_ in segments_:\n",
    "        if segment_[1] in visited:\n",
    "            visited[segment_[1]] += 1\n",
    "        else:\n",
    "            visited[segment_[1]] = 1\n",
    "\n",
    "        if segment_[2] in visited:\n",
    "            visited[segment_[2]] += 1\n",
    "        else:\n",
    "            visited[segment_[2]] = 1\n",
    "        \n",
    "    for indx, segment_ in enumerate(segments_):\n",
    "        carry1 = segment_[1]\n",
    "        carry2 = segment_[2]\n",
    "        if carry1 not in seen:\n",
    "            if visited[carry1] == 1:\n",
    "                time = time_lookup(carry1)\n",
    "                start = time[3]\n",
    "                end   = time[4]\n",
    "                seen[carry1] = True\n",
    "            else:\n",
    "                time = time_lookup(carry1)\n",
    "                start = time[1]\n",
    "                end   = time[2]\n",
    "\n",
    "\n",
    "\n",
    "    for segment_ in segments_:\n",
    "        for i in time_window_df.values.tolist():\n",
    "            if i[0] == segment_[1]: \n",
    "                first = i\n",
    "                break\n",
    "        if (first[1] == 'DIA') or (pd.isna(first[1])) or (first[0] in seen_):\n",
    "            start = i[3]\n",
    "            end   = i[4]\n",
    "        else:\n",
    "            start = i[1]\n",
    "            end = i[2]\n",
    "            seen_[i[0]] = True\n",
    "        if segment_[2] == 0: \n",
    "            return (pd.to_datetime(start), pd.to_datetime(end))\n",
    "\n",
    "        # If there is a second carry-in site, explore that one as well\n",
    "        for i in time_window_df.values.tolist():\n",
    "            if i[0] == segment_[1]: \n",
    "                second = i\n",
    "                break\n",
    "        if (second[1] == 'DIA') or (pd.isna(second[1])) or (second[0] in seen):\n",
    "            start2 = i[3]\n",
    "            end2   = i[4]\n",
    "        else:\n",
    "            start = i[1]\n",
    "            end = i[2]\n",
    "            seen[i[0]] = True \n",
    "\n",
    "    # Compare between the two start and end times\n",
    "    if pd.to_datetime(start) < pd.to_datetime(start2):\n",
    "        start = pd.to_datetime(start)\n",
    "    else: \n",
    "        start = pd.to_datetime(start2)\n",
    "    \n",
    "    if pd.to_datetime(end) < pd.to_datetime(end2):\n",
    "        end = pd.to_datetime(end)\n",
    "    else:\n",
    "        end = pd.to_datetime(end2)\n",
    "\n",
    "    return (start, end)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(450, 604, 0),\n (450, 604, 0),\n (292, 181, 0),\n (292, 181, 0),\n (423, 490, 0),\n (423, 490, 0),\n (423, 477, 801),\n (423, 477, 801),\n (214, 192, 0),\n (214, 192, 0),\n (437, 252, 0),\n (218, 999, 0),\n (984, 394, 0),\n (682, 891, 0),\n (682, 532, 602),\n (682, 515, 0),\n (682, 602, 0),\n (682, 497, 515),\n (682, 532, 0),\n (461, 479, 478),\n (461, 479, 478),\n (451, 213, 0),\n (451, 212, 0),\n (451, 212, 213),\n (981, 110, 0),\n (981, 110, 0),\n (405, 264, 0),\n (258, 179, 0),\n (258, 179, 0),\n (248, 168, 0),\n (301, 438, 0),\n (408, 316, 158),\n (408, 158, 316),\n (982, 516, 0),\n (982, 516, 0),\n (464, 499, 0),\n (464, 499, 0),\n (464, 436, 0),\n (412, 223, 203),\n (419, 522, 0),\n (419, 522, 0),\n (424, 509, 0),\n (455, 383, 0),\n (455, 605, 383),\n (455, 488, 0),\n (455, 488, 605),\n (150, 161, 0),\n (150, 161, 0),\n (190, 750, 0),\n (415, 426, 0),\n (415, 426, 473),\n (971, 117, 0),\n (971, 117, 0),\n (275, 533, 0),\n (278, 178, 0),\n (457, 328, 0),\n (457, 328, 0)]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: (Timestamp('2020-05-13 06:15:00'), Timestamp('2020-05-13 07:15:00')),\n 1: (Timestamp('2020-05-13 09:30:00'), Timestamp('2020-05-13 10:30:00')),\n 2: (Timestamp('2020-05-13 06:10:00'), Timestamp('2020-05-13 07:10:00')),\n 3: (Timestamp('2020-05-13 09:45:00'), Timestamp('2020-05-13 10:45:00')),\n 4: (Timestamp('2020-05-13 07:00:00'), Timestamp('2020-05-13 08:00:00')),\n 5: (Timestamp('2020-05-13 10:15:00'), Timestamp('2020-05-13 11:15:00')),\n 6: (Timestamp('2020-05-13 09:15:00'), Timestamp('2020-05-13 11:15:00')),\n 7: (Timestamp('2020-05-13 09:15:00'), Timestamp('2020-05-13 11:15:00')),\n 8: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 9: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 10: (Timestamp('2020-05-13 03:45:00'), Timestamp('2020-05-13 11:45:00')),\n 11: (Timestamp('2020-05-13 09:45:00'), Timestamp('2020-05-13 10:45:00')),\n 12: (Timestamp('2020-05-13 06:30:00'), Timestamp('2020-05-13 06:31:00')),\n 13: (Timestamp('2020-05-13 08:15:00'), Timestamp('2020-05-13 09:15:00')),\n 14: (Timestamp('2020-05-13 06:30:00'), Timestamp('2020-05-13 07:30:00')),\n 15: (Timestamp('2020-05-13 06:30:00'), Timestamp('2020-05-13 07:30:00')),\n 16: (Timestamp('2020-05-13 07:30:00'), Timestamp('2020-05-13 07:45:00')),\n 17: (Timestamp('2020-05-13 06:30:00'), Timestamp('2020-05-13 07:30:00')),\n 18: (Timestamp('2020-05-13 10:50:00'), Timestamp('2020-05-13 11:50:00')),\n 19: (Timestamp('2020-05-13 06:45:00'), Timestamp('2020-05-13 07:45:00')),\n 20: (Timestamp('2020-05-13 09:35:00'), Timestamp('2020-05-13 10:35:00')),\n 21: (Timestamp('2020-05-13 08:00:00'), Timestamp('2020-05-13 08:15:00')),\n 22: (Timestamp('2020-05-13 09:00:00'), Timestamp('2020-05-13 11:00:00')),\n 23: (Timestamp('2020-05-13 09:00:00'), Timestamp('2020-05-13 11:00:00')),\n 24: (Timestamp('2020-05-13 08:40:00'), Timestamp('2020-05-13 10:40:00')),\n 25: (Timestamp('2020-05-13 08:40:00'), Timestamp('2020-05-13 10:40:00')),\n 26: (Timestamp('2020-05-13 02:45:00'), Timestamp('2020-05-13 10:45:00')),\n 27: (Timestamp('2020-05-13 08:15:00'), Timestamp('2020-05-13 10:15:00')),\n 28: (Timestamp('2020-05-13 08:15:00'), Timestamp('2020-05-13 10:15:00')),\n 29: (Timestamp('2020-05-13 09:15:00'), Timestamp('2020-05-13 11:15:00')),\n 30: (Timestamp('2020-05-13 08:32:00'), Timestamp('2020-05-13 10:32:00')),\n 31: (Timestamp('2020-05-13 06:25:00'), Timestamp('2020-05-13 07:25:00')),\n 32: (Timestamp('2020-05-13 08:40:00'), Timestamp('2020-05-13 10:40:00')),\n 33: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 34: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 35: (Timestamp('2020-05-13 07:30:00'), Timestamp('2020-05-13 07:45:00')),\n 36: (Timestamp('2020-05-13 11:15:00'), Timestamp('2020-05-13 11:30:00')),\n 37: (Timestamp('2020-05-13 09:30:00'), Timestamp('2020-05-13 11:30:00')),\n 38: (Timestamp('2020-05-13 03:15:00'), Timestamp('2020-05-13 11:15:00')),\n 39: (Timestamp('2020-05-13 06:15:00'), Timestamp('2020-05-13 07:15:00')),\n 40: (Timestamp('2020-05-13 09:56:00'), Timestamp('2020-05-13 10:56:00')),\n 41: (Timestamp('2020-05-13 10:59:00'), Timestamp('2020-05-13 11:14:00')),\n 42: (Timestamp('2020-05-13 06:25:00'), Timestamp('2020-05-13 07:25:00')),\n 43: (Timestamp('2020-05-13 08:35:00'), Timestamp('2020-05-13 10:35:00')),\n 44: (Timestamp('2020-05-13 05:45:00'), Timestamp('2020-05-13 06:45:00')),\n 45: (Timestamp('2020-05-13 09:45:00'), Timestamp('2020-05-13 10:45:00')),\n 46: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 47: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 48: (Timestamp('2020-05-13 09:45:00'), Timestamp('2020-05-13 10:45:00')),\n 49: (Timestamp('2020-05-13 08:30:00'), Timestamp('2020-05-13 10:30:00')),\n 50: (Timestamp('2020-05-13 08:30:00'), Timestamp('2020-05-13 10:30:00')),\n 51: (Timestamp('2020-05-13 08:35:00'), Timestamp('2020-05-13 10:35:00')),\n 52: (Timestamp('2020-05-13 08:35:00'), Timestamp('2020-05-13 10:35:00')),\n 53: (Timestamp('2020-05-13 09:30:00'), Timestamp('2020-05-13 11:30:00')),\n 54: (Timestamp('2020-05-13 02:30:00'), Timestamp('2020-05-13 10:30:00')),\n 55: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00')),\n 56: (Timestamp('2020-05-13 08:45:00'), Timestamp('2020-05-13 10:45:00'))}"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "timewindow = {}\n",
    "seen = {}\n",
    "for indx, val in enumerate(segments):\n",
    "    timewindow[indx] = window_builder(val, seen)\n",
    "timewindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Service Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "49"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting prep sites\n",
    "# Expressing distance matrix as list of lists \n",
    "# Marking the depot as having code '0'\n",
    "prep = timedf.index.values \n",
    "dist = [list(i) for i in list(timedf.values)]\n",
    "depot = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a dictionary which maps a prep site's 3 digit code to it's node in the graph\n",
    "## site_to_indx[174] -> 0\n",
    "site_to_indx = {}\n",
    "for indx, site in enumerate(prep):\n",
    "    site_to_indx[site] = indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes two prep sites and returns the distance between them. Distances are not symetrical. \n",
    "## (174, 1109) -> 14.74\n",
    "## (1109, 174) -> 15.59\n",
    "def distance(i, j):\n",
    "    return dist[site_to_indx[i]][site_to_indx[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculates the savings from merging two prep sites i, j. \n",
    "def savings(prep_, depot_, distance_):\n",
    "    savings = []\n",
    "    for i in prep_:\n",
    "        if i == depot_: continue\n",
    "        for j in prep_:\n",
    "            if (j==depot_) or (i==j): \n",
    "                continue \n",
    "            i_cost = distance(i, depot_)\n",
    "            j_cost = distance(depot_, i)\n",
    "            ij_cost = distance(i, j)\n",
    "            save = i_cost + j_cost - ij_cost\n",
    "            savings.append(((i,j), save))\n",
    "    return savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the savings such that highest savings is on bottom\n",
    "savings_ls = savings(prep, depot, dist)\n",
    "savings_ls.sort(key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a graph and applying the savings algorithm\n",
    "graph = Graph(prep, depot)\n",
    "i = 0\n",
    "while i<1000:\n",
    "    x = savings_ls.pop()\n",
    "    node1 = x[0][0]\n",
    "    node2 = x[0][1]\n",
    "    if not graph.is_node_interior(node1) and not graph.is_node_interior(node2):\n",
    "        if not graph.on_same_route(x[0]):\n",
    "            graph.merge(x[0])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Build the dataframe for the graph\n",
    "selected_arcs = list(graph.arcs)\n",
    "start = [i[0] for i in selected_arcs]\n",
    "end = [i[1] for i in selected_arcs]\n",
    "df = pd.DataFrame({ 'from':start, 'to':end})\n",
    " \n",
    "# Build your graph\n",
    "G=nx.from_pandas_edgelist(df, 'from', 'to')\n",
    " \n",
    " \n",
    "# Plot it\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}